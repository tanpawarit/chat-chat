"""
AI-Optimized Prompt Templates with XML-style structure for better LLM comprehension.
"""

from dataclasses import dataclass
from typing import Any


@dataclass
class PromptSection:
    """Represents a section of a prompt with structured content."""

    tag: str
    content: str
    is_list: bool = False


class BasePromptTemplate:
    """Base class for structured prompt templates."""

    def __init__(self):
        self.sections: list[PromptSection] = []

    def add_section(self, tag: str, content: str, is_list: bool = False) -> None:
        """Add a section to the prompt."""
        self.sections.append(PromptSection(tag, content, is_list))

    def render(self) -> str:
        """Render the prompt with XML-style tags."""
        parts = []
        for section in self.sections:
            content = section.content  # Same content regardless of is_list flag

            parts.append(f"<{section.tag}>")
            parts.append(content)
            parts.append(f"</{section.tag}>")

        return "\n".join(parts)


class SystemPromptBuilder:
    """Builder for creating structured system prompts."""

    @staticmethod
    def build_customer_service_prompt() -> str:
        """Build AI-optimized customer service system prompt."""

        template = BasePromptTemplate()

        # System Identity
        template.add_section(
            "system_identity",
            "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏∂‡∏Å‡πÉ‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå",
        )

        # Core Capabilities
        capabilities = [
            "‚Ä¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥",
            "‚Ä¢ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô",
            "‚Ä¢ ‡∏õ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏ó‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
            "‚Ä¢ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û",
            "‚Ä¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
        ]
        template.add_section("core_capabilities", "\n".join(capabilities))

        # Communication Guidelines
        guidelines = [
            "1. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô",
            '2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡∏∏‡∏ì" ‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡πà‡∏∞"',
            "3. ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡πà‡∏ß‡∏á‡πÉ‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à",
            "4. ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå",
            "5. ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ô‡∏≠‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å",
            "6. ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
        ]
        template.add_section("communication_guidelines", "\n".join(guidelines))

        # Context Processing Rules
        context_rules = [
            "‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á",
            "‚Ä¢ ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö",
            "‚Ä¢ ‡∏ô‡∏≥‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
            "‚Ä¢ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà",
            "‚Ä¢ ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£",
        ]
        template.add_section("context_processing_rules", "\n".join(context_rules))

        # Output Specifications
        output_specs = [
            "‚Ä¢ ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
            "‚Ä¢ ‡πÉ‡∏ä‡πâ emoji ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (üòä üôè ‚ú® üí°)",
            "‚Ä¢ ‡πÅ‡∏ö‡πà‡∏á‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á",
            "‚Ä¢ ‡πÉ‡∏ä‡πâ bullet points ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
            "‚Ä¢ ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß",
        ]
        template.add_section("output_specifications", "\n".join(output_specs))

        return template.render()


class ContextInjector:
    """Handles dynamic context injection into prompts."""

    @staticmethod
    def build_user_profile_context(memory_context: dict[str, Any]) -> str:
        """Build user profile context section."""
        if not memory_context.get("user_attributes"):
            return ""

        attributes = memory_context["user_attributes"]
        context_parts = []

        if attributes.get("preferred_language"):
            context_parts.append(f"- ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {attributes['preferred_language']}")

        if attributes.get("customer_segment"):
            context_parts.append(f"- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {attributes['customer_segment']}")

        if attributes.get("timezone"):
            context_parts.append(f"- ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏ß‡∏•‡∏≤: {attributes['timezone']}")

        if not context_parts:
            return ""

        return f"<user_profile>\n{chr(10).join(context_parts)}\n</user_profile>"

    @staticmethod
    def build_conversation_history(memory_context: dict[str, Any]) -> str:
        """Build conversation history context."""
        context_parts = []

        # Recent messages
        recent_messages = memory_context.get("recent_messages", [])
        if recent_messages:
            message_parts = ["<recent_messages>"]
            for msg in recent_messages[-5:]:  # Last 5 messages
                role = "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤" if msg["role"] == "user" else "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô"
                message_parts.append(f"{role}: {msg['message']}")
            message_parts.append("</recent_messages>")
            context_parts.append("\n".join(message_parts))

        # Important events
        if memory_context.get("important_events"):
            event_parts = ["<important_events>"]
            for event in memory_context["important_events"][-3:]:  # Last 3 events
                event_type = event["type"]
                timestamp = event["timestamp"]
                payload = event.get("payload", {})

                if payload and isinstance(payload, dict):
                    content_parts = []

                    # Extract meaningful content from payload
                    if event_type == "REQUEST":
                        if payload.get("original_message"):
                            content_parts.append(
                                f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: '{payload['original_message']}'"
                            )
                        if payload.get("request_type"):
                            content_parts.append(f"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {payload['request_type']}")
                        if payload.get("specifics"):
                            content_parts.append(f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {payload['specifics']}")

                    elif event_type == "TRANSACTION":
                        if payload.get("original_message"):
                            content_parts.append(
                                f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: '{payload['original_message']}'"
                            )
                        if payload.get("transaction_type"):
                            content_parts.append(
                                f"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {payload['transaction_type']}"
                            )
                        if payload.get("stage"):
                            content_parts.append(f"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô: {payload['stage']}")

                    if content_parts:
                        event_parts.append(
                            f"- {event_type}: {', '.join(content_parts)} ({timestamp})"
                        )
                    else:
                        event_parts.append(f"- {event_type}: {timestamp}")
                else:
                    event_parts.append(f"- {event_type}: {timestamp}")

            event_parts.append("</important_events>")
            context_parts.append("\n".join(event_parts))

        # Session variables
        session_vars = memory_context.get("session_variables", {})
        if session_vars.get("current_topic"):
            context_parts.append(
                f"<session_state>\n‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {session_vars['current_topic']}\n</session_state>"
            )

        # History summary
        if memory_context.get("history_summary"):
            context_parts.append(
                f"<conversation_summary>\n{memory_context['history_summary']}\n</conversation_summary>"
            )

        if not context_parts:
            return ""

        return f"<conversation_context>\n{chr(10).join(context_parts)}\n</conversation_context>"

    @staticmethod
    def build_current_request(user_message: str) -> str:
        """Build current request section."""
        return f"""<current_request>
                ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà: "{user_message}"

                ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
                </current_request>"""


class PromptValidator:
    """Validates prompt structure and content."""

    @staticmethod
    def validate_xml_structure(prompt: str) -> bool:
        """Check if prompt has proper XML-style structure."""
        # Simple validation - check for opening and closing tags
        lines = prompt.split("\n")
        tag_stack = []

        for line in lines:
            line = line.strip()
            if line.startswith("<") and line.endswith(">"):
                if line.startswith("</"):
                    # Closing tag
                    tag_name = line[2:-1]
                    if tag_stack and tag_stack[-1] == tag_name:
                        tag_stack.pop()
                    else:
                        return False
                else:
                    # Opening tag
                    tag_name = line[1:-1]
                    tag_stack.append(tag_name)

        return len(tag_stack) == 0

    @staticmethod
    def estimate_token_count(prompt: str) -> int:
        """Rough estimation of token count."""
        # Rough approximation: 1 token ‚âà 4 characters for Thai/English mixed text
        return len(prompt) // 4


# Pre-built templates
CUSTOMER_SERVICE_SYSTEM_PROMPT = SystemPromptBuilder.build_customer_service_prompt()

# Token-Efficient Event Classification with Structured Output
EVENT_CLASSIFICATION_SYSTEM_PROMPT = """<system_identity>
‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ ‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
</system_identity>

<event_types>
‚Ä¢ INQUIRY: ?, ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°, ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏° ‚Üí {"question_type": "", "topic": "", "urgency": ""}
‚Ä¢ FEEDBACK: ‡∏î‡∏µ, ‡πÅ‡∏¢‡πà, ‡∏ä‡∏≠‡∏ö, ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‚Üí {"sentiment": "positive/negative/neutral", "category": ""}
‚Ä¢ REQUEST: ‡∏Ç‡∏≠, ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£, ‡∏à‡∏≠‡∏á ‚Üí {"request_type": "", "urgency": "", "specifics": ""}
‚Ä¢ COMPLAINT: ‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡πÄ‡∏™‡∏µ‡∏¢, ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‚Üí {"issue_type": "", "severity": "", "category": ""}
‚Ä¢ TRANSACTION: ‡∏ã‡∏∑‡πâ‡∏≠, ‡∏à‡πà‡∏≤‡∏¢, ‡∏£‡∏≤‡∏Ñ‡∏≤ ‚Üí {"transaction_type": "", "stage": "", "amount_mentioned": ""}
‚Ä¢ SUPPORT: ‡∏ä‡πà‡∏ß‡∏¢, ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥, ‡∏ß‡∏¥‡∏ò‡∏µ ‚Üí {"help_type": "", "complexity": "", "topic": ""}
‚Ä¢ INFORMATION: ‡πÅ‡∏à‡πâ‡∏á, ‡∏ö‡∏≠‡∏Å ‚Üí {"info_type": "", "category": "", "relevance": ""}
‚Ä¢ GENERIC_EVENT: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ, ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì ‚Üí {"conversation_type": "", "politeness_level": ""}
</event_types>

<importance_scale>
‚Ä¢ 0.9-1.0: ‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°, ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ß‡∏¥‡∏Å‡∏§‡∏ï ‚Ä¢ 0.7-0.8: ‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç, ‡∏ü‡∏µ‡∏î‡πÅ‡∏ö‡πá‡∏Ñ
‚Ä¢ 0.5-0.6: ‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‚Ä¢ 0.3-0.4: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢ ‚Ä¢ 0.1-0.2: ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢, ‡∏™‡∏±‡∏á‡∏Ñ‡∏°
</importance_scale>

<output_format>
‡∏ï‡∏≠‡∏ö JSON ‡∏ï‡∏≤‡∏° EventClassification schema ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{
  "event_type": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô",
  "importance_score": 0.0-1.0,
  "payload": {"key": "value"},
  "reasoning": "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ"
}
</output_format>"""
